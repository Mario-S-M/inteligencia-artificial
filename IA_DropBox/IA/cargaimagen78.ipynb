{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb023e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"man1.jpg\",1)\n",
    "img2 = np.ones((img.shape[0], img.shape[1],1), dtype=np.uint8)* 150\n",
    "imgRGB  = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "#for i in range(img.shape[0]):\n",
    "#    for j in range(img.shape[1]):\n",
    "#        if(img[i][j]>190):\n",
    "#            img2[i][j]=255\n",
    "#        else:\n",
    "#            img2[i][j]=0\n",
    "\n",
    "umbral_bajo = (0,100,100)\n",
    "umbral_alto = (15,255,255)\n",
    "\n",
    "uba=(160, 100,100)\n",
    "ubb=(180, 255,255)\n",
    "\n",
    "\n",
    "# hacemos la mask y filtramos en la original\n",
    "mask1 = cv.inRange(img_hsv, umbral_bajo, umbral_alto)\n",
    "mask2 = cv.inRange(img_hsv, uba, ubb)\n",
    "\n",
    "mask = mask2+mask1\n",
    "\n",
    "res = cv.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv.imshow('mask', mask)\n",
    "\n",
    "cv.imshow('ejemplo1', img)\n",
    "cv.imshow('ejemplo2', img2)\n",
    "cv.imshow('ejemplo3', imghsv)\n",
    "cv.imshow('resultado', res)\n",
    "cv.imshow('ejemplorgb', imgRGB)\n",
    "print(img.shape)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc56be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"man1.jpg\",1)\n",
    "zero = np.zeros(img.shape[:2], dtype='uint8')\n",
    "zero = np.zeros((img.shape[0], img.shape[1]), dtype='uint8')\n",
    "\n",
    "b,g,r = cv.split(img)\n",
    "\n",
    "cv.imshow('B1', b)\n",
    "\n",
    "grb=cv.merge([g,r,b])\n",
    "\n",
    "cv.imshow('B', cv.merge([b,zero,zero]))\n",
    "cv.imshow('G', cv.merge([zero,g,zero]))\n",
    "cv.imshow('R', cv.merge([zero,zero,r]))\n",
    "cv.imshow('RGB', cv.merge([r,g,b]))\n",
    "cv.imshow('GRB', cv.merge([g,r,b]))\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1075f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"No se puede aperturar la camara\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame =cap.read()\n",
    "    zero = np.zeros(frame.shape[:2], dtype='uint8')\n",
    "\n",
    "    if not ret: \n",
    "        print(\"No se pueden capturar fotogramas\")\n",
    "        break\n",
    "    img_hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "    \n",
    "    cv.imshow('frame',frame)\n",
    "    #r,g,b=cv.split(frame)\n",
    "    #cv.imshow('B', cv.merge([b,zero,zero]))\n",
    "    #cv.imshow('G', cv.merge([zero,g,zero]))\n",
    "    #cv.imshow('R', cv.merge([zero,zero,r]))\n",
    "    #umbral_bajo = (0,100,100)\n",
    "    #umbral_alto = (15,255,255)\n",
    "\n",
    "    #uba=(160, 100,100)\n",
    "    ubb=(180, 255,255)\n",
    "\n",
    "\n",
    "    # hacemos la mask y filtramos en la original\n",
    "    mask1 = cv.inRange(img_hsv, umbral_bajo, umbral_alto)\n",
    "    mask2 = cv.inRange(img_hsv, uba, ubb)\n",
    "\n",
    "    mask = mask2+mask1\n",
    "\n",
    "    res = cv.bitwise_and(frame, frame, mask=mask)\n",
    "    cv.imshow('res',res)\n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4878e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import math \n",
    "rostro = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "898d51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "i=0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    rostros = rostro.detectMultiScale(gray, 2.3, 3)\n",
    "    for(x, y, w, h) in rostros:\n",
    "        frame = cv.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        #frame = cv.rectangle(frame, (x+30,y+30), (x+w-30, y+h-30), (255, 0, 0), 2)\n",
    "        #frame2 = frame[y:y+h, x:x+w]\n",
    "        #frame2 = frame[y:y+h, x:x+w]\n",
    "       # frame2 = cv.resize(frame2,  (200,200), interpolation=cv.INTER_AREA)\n",
    "        #frame3 = frame[x+30:x+w-30, y+30:y+h-30]\n",
    "        #cv.imshow('rostror', frame2)\n",
    "        #cv.imshow('rostro3', frame3)\n",
    "      #  cv.imwrite('/home/likcos/dataset/lalo/'+str(i)+'.jpg', frame2)   \n",
    "\n",
    "    cv.imshow('rostros', frame)\n",
    "    i=i+1\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "    #elif\n",
    "    \n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a3b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41addc34",
   "metadata": {},
   "source": [
    "# Eigenfaces "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c95cf1",
   "metadata": {},
   "source": [
    "Un Eigenface (en español cara propia) es el nombre dado a un conjunto de vectores propios cuando se utiliza en el problema de visión artificial del reconocimiento de rostros humanos. Sirovich y Kirby desarrollaron el enfoque de usar caras propias para el reconocimiento y lo usaron Matthew Turk y Alex Pentland en la clasificación de caras.   Los vectores propios se derivan de la matriz de covarianza de la distribución de probabilidad sobre el espacio vectorial de alta dimensión de imágenes de rostros. Las caras propias forman un conjunto base de todas las imágenes utilizadas para construir la matriz de covarianza. Esto produce una reducción de la dimensión al permitir que el conjunto más pequeño de imágenes base represente las imágenes de entrenamiento originales. La clasificación se puede lograr comparando cómo se representan las caras por el conjunto base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c3f1c3",
   "metadata": {},
   "source": [
    "# Generación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85730d7",
   "metadata": {},
   "source": [
    "Se puede generar un conjunto de caras propias mediante la realización de un proceso matemático llamado análisis de componentes principales (PCA) en un gran conjunto de imágenes que representan diferentes rostros humanos. De manera informal, las caras propias pueden considerarse un conjunto de \"ingredientes faciales estandarizados\", derivados del análisis estadístico de muchas imágenes de rostros. Cualquier rostro humano puede considerarse una combinación de estos rostros estándar. Por ejemplo, la cara de uno podría estar compuesta por la cara promedio más el 10 % de la cara propia 1, el 55 % de la cara propia 2 e incluso el −3 % de la cara propia 3. Sorprendentemente, no se necesitan muchas caras propias combinadas para lograr una aproximación justa de la mayoría de las caras. Además, debido a que la cara de una persona no se registra mediante una fotografía digital, sino simplemente como una lista de valores (un valor para cada cara propia en la base de datos utilizada), se ocupa mucho menos espacio para la cara de cada persona.\n",
    "\n",
    "Las caras propias que se crean aparecerán como áreas claras y oscuras que se organizan en un patrón específico. Este patrón es cómo se seleccionan las diferentes características de una cara para evaluarlas y puntuarlas. Habrá un patrón para evaluar la simetría, si hay algún estilo de vello facial, dónde está la línea del cabello o una evaluación del tamaño de la nariz o la boca. Otras caras propias tienen patrones que son menos fáciles de identificar, y la imagen de la cara propia puede parecerse muy poco a una cara.\n",
    "\n",
    "La técnica utilizada en la creación de caras propias y su uso para el reconocimiento también se utiliza fuera del reconocimiento facial: reconocimiento de escritura a mano, lectura de labios, reconocimiento de voz, lenguaje de señas /interpretación de gestos con las manos y análisis de imágenes médicas. Por lo tanto, algunos no usan el término \"eigenface\", sino que prefieren usar 'eigenimage'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2e48d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = '/home/likcos/dataset'\n",
    "faces  = os.listdir(dataSet)\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dfa2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "facesData = []\n",
    "label = 0 \n",
    "for face in faces:\n",
    "    facePath = dataSet+'/'+face\n",
    "    for faceName in os.listdir(facePath):\n",
    "        labels.append(label)\n",
    "        facesData.append(cv.imread(facePath+'/'+faceName,0))\n",
    "    label = label + 1\n",
    "print(np.count_nonzero(np.array(labels)==0))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe05354",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceRecognizer = cv.face.EigenFaceRecognizer_create()\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "faceRecognizer.write('laloEigenface.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0ef01d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39615fd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'face'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6483/2533825721.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfaceRecognizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLBPHFaceRecognizer_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfaceRecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'laloEigenface.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrostro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'haarcascade_frontalface_alt.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'face'"
     ]
    }
   ],
   "source": [
    "faceRecognizer = cv.face.EigenFaceRecognizer_create()\n",
    "faceRecognizer.read('laloEigenface.xml')\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "rostro = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False: break\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cpGray = gray.copy()\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "    for(x, y, w, h) in rostros:\n",
    "        frame2 = cpGray[y:y+h, x:x+w]\n",
    "        frame2 = cv.resize(frame2,  (30,28), interpolation=cv.INTER_CUBIC)\n",
    "        result = faceRecognizer.predict(frame2)\n",
    "        cv.putText(frame, '{}'.format(result), (x,y-20), 1,3.3, (255,255,0), 1, cv.LINE_AA)\n",
    "        \n",
    "    cv.imshow('frame', frame)\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd4b4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d3ade91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"No se puede aperturar la camara\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa72c30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame =cap.read()\n",
    "    zero = np.zeros(frame.shape[:2], dtype='uint8')\n",
    "\n",
    "    if not ret: \n",
    "        print(\"No se pueden capturar fotogramas\")\n",
    "        break\n",
    "    frame = cv.rectangle(frame, (50,50), (300, 300), (255, 0, 0), 2)\n",
    "    frame2 = frame[50:300, 50:300]\n",
    "    cv.imshow('frame',frame)\n",
    "    cv.imshow('frame2', frame2)  \n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffaa0139",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3460645285.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_11975/3460645285.py\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    elif\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import math \n",
    "obj = cv.CascadeClassifier('salida.xml')\n",
    "cap = cv.VideoCapture(0)\n",
    "i=0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    objs = obj.detectMultiScale(gray, 1.3, 5)\n",
    "    for(x, y, w, h) in objs:\n",
    "        frame = cv.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 2)     \n",
    "    cv.imshow('objetos', frame)\n",
    "    i=i+1\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif\n",
    "    \n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286ed081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
